{"version":3,"sources":["../../../source/Tokenizer/StopWordsTokenizer.js"],"names":["StopWordsTokenizer","decoratedTokenizer","_tokenizer","text","tokenize","filter","token"],"mappings":";;;;;;;;;AAIA;;;;AAEA;;;;;IAKaA,kB,WAAAA,kB;;AAGX;;;;;AAKA,8BAAYC,kBAAZ,EAA6C;AAAA;;AAC3C,SAAKC,UAAL,GAAkBD,kBAAlB;AACD;;AAED;;;;;;;6BAGSE,I,EAA+B;AACtC,aAAO,KAAKD,UAAL,CAAgBE,QAAhB,CAAyBD,IAAzB,EACJE,MADI,CAEH,UAACC,KAAD;AAAA,eAAW,CAAC,2BAAaA,KAAb,CAAZ;AAAA,OAFG,CAAP;AAID;;;;;;AACF","file":"StopWordsTokenizer.js","sourcesContent":["// @flow\n\nimport type { ITokenizer } from './Tokenizer';\n\nimport { StopWordsMap } from '../StopWordsMap';\n\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\nexport class StopWordsTokenizer implements ITokenizer {\n  _tokenizer : ITokenizer;\n\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  constructor(decoratedTokenizer : ITokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n\n  /**\n   * @inheritDocs\n   */\n  tokenize(text : string) : Array<string> {\n    return this._tokenizer.tokenize(text)\n      .filter(\n        (token) => !StopWordsMap[token]\n      );\n  }\n};\n"]}